# -*- coding: utf-8 -*-
"""Dicoding - ML Terapan_Submission 3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MJ7WQJ-bkNEfDz5fiupSuo6aCjSnrSFX
"""

# Import library
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from zipfile import ZipFile
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from pathlib import Path
from sklearn.model_selection import train_test_split

"""# Data Understanding

Dataset yang digunakan dalam proyek ini merupakan dataset film yang digunakan untuk membangun sistem rekomendasi berdasarkan preferensi pengguna. Dataset ini terdiri dari dua file yaitu movies.csv dan ratings.csv. Pada file movies.csv terdiri dari 3 kolom dengan 9742 baris data. Sedangkan, pada file rating.csv terdiri dari 4 kolom dengan 100836 baris data. Dataset ini diperoleh dari Kaggle melalui tautan berikut: (https://www.kaggle.com/datasets/nicoletacilibiu/movies-and-ratings-for-recommendation-system)

Variabel dalam file movies.csv:
* movieId - ID unik untuk setiap film.
* title - Judul film.
* genres - Genre film (misalnya, aksi, drama, komedi, dll).


Variabel dalam file ratings.csv:
* userId - ID unik untuk setiap pengguna yang memberikan rating.
* movieId - ID film yang diberi rating oleh pengguna.
* rating - Rating yang diberikan oleh pengguna
* timestamp - Waktu ketika rating diberikan.
"""

import pandas as pd

df1 = pd.read_csv('/content/movies.csv')
df2 = pd.read_csv('/content/ratings.csv')
df1

df2

"""Kondisi Data Movies.csv:

* variabel title dan genres memiliki tipe data object. Sementara variabel movieId bertipe data Integer.
* Missing Value: Tidak ditemukan nilai yang hilang karena semua kolom memiliki 9742 non-null count.
* Duplikasi: Tidak ada indikasi duplikasi berdasarkan informasi yang diberikan.
"""

df1.info()

df1.describe()

"""Kondisi Data Ratings.csv:

* Semua variabel berbentuk numerik dengan tipe data int64 (userId, movieId, timestamp) dan int64 (rating).
* Missing Value: Tidak ditemukan nilai yang hilang karena semua kolom memiliki 100836 non-null count.
* Duplikasi: Tidak ada indikasi duplikasi berdasarkan informasi yang diberikan.
"""

df2.info()

"""Berdasarkan statiska deskriptif, variabel rating memiliki nilai terkecil 0.5 dan nilai terbesar 5, sehingga rentang nilai rating yang diberikan user antara 0.5 sampai dengan 5"""

df2.describe()

import pandas as pd
import matplotlib.pyplot as plt

# Memisahkan genre yang digabung dengan "|"
all_genres = df1['genres'].str.split('|').explode()  # Mengubah menjadi satu genre per baris

# Menghitung jumlah kemunculan setiap genre
genre_counts = all_genres.value_counts()

# Visualisasi dengan Diagram Batang
plt.figure(figsize=(12, 8))
genre_counts.plot(kind='bar', color=plt.cm.Paired.colors)
plt.title('Kategori Genre Film')
plt.xlabel('Genre')
plt.ylabel('Jumlah Film')
plt.xticks(rotation=45, ha='right')  # Memiringkan label genre agar lebih mudah dibaca
plt.tight_layout()  # Menyesuaikan layout agar tidak terpotong
plt.show()

"""Berdasarkan visualisasi grafik batang di atas. Dapat dilihat bahwa genres film terbanyak secara berurutan adalah genre Drama, Comedy, Thriller, Action, dst. Informasi ini dapat digunakan oleh perusahaan penyedia streaming film untuk merekomendasikan film dengan genre-genres tertentu yang memang paling disukai oleh pengguna"""

plt.hist(df2.rating)
plt.ylabel('Total')
plt.xlabel('Avg Rating')
plt.title("Film's Ratings Distribution")
plt.show()

"""Berdasarkan gambar persebaran nilai rating yang diberikan user, terlihat bahwa nilai terbanyak adalah nilai dengan rating 4. Kemudian, disusul dengan nilai rating 3. Sementara itu, nilai terkecil yang diberikan user adalah 0,5 dan nilai terbesar adalah 5.

# Data Preparation

Melakukan konversi dataseries menjadi list menggunakan fungsi tolist() dari library numpy
"""

# Mengonversi data series ‘placeID’ menjadi dalam bentuk list
movieId = df1['movieId'].tolist()

# Mengonversi data series ‘Name’ menjadi dalam bentuk list
title = df1['title'].tolist()

# Mengonversi data series ‘Rcuisine’ menjadi dalam bentuk list
genres = df1['genres'].tolist()

print(len(movieId))
print(len(title))
print(len(genres))

"""# Model Development Content Based Filtering

Tahap ini akan dibuat dictionary untuk menentukan pasangan key-value pada data movieId, title, dan genres yang telah kita siapkan sebelumnya.
"""

# Membuat dictionary untuk data ‘movies_id’, ‘title’, dan ‘genres’
movies_new = pd.DataFrame({
    'id': movieId,
    'title': title,
    'genres': genres
})
movies_new

data = movies_new
data.sample(5)

"""## TF-IDF Vectorizer

Pada tahap ini akan dibuat sistem rekomendasi sederhana berdasarkan jenis genre film menggunakan teknik TF-IDF Vectorizer yang menemukan representasi fitur penting dari setiap kategori genre film
"""

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
tfid = TfidfVectorizer()
tfid.fit(data['genres'])

tfid.get_feature_names_out()

"""Selanjutnya, akan dilakukan fit dan transformasi ke dalam bentuk matriks.   Output yang dihasilkan berupa matriks berukuran (9724, 24). Nilai 9724 merupakan ukuran data dan 24 merupakan matrik kategori genres film."""

tfidf_matrix = tfid.fit_transform(data['genres'])


tfidf_matrix.shape

"""Untuk menghasilkan vektor tf-idf dalam bentuk matriks digunakan fungsi todense()."""

tfidf_matrix.todense()

pd.DataFrame(
    tfidf_matrix.todense(),
    columns=tfid.get_feature_names_out(),
    index=data.title
).sample(24, axis=1).sample(10, axis=0)

"""Output matriks tf-idf di atas menunjukkan hubungan antara film dengan genrenya. Sebagai contoh, film dengan judul Dinner Game, The (Dîner de cons, Le) (1998) memiliki nilai matriks 1.0 pada kategori Comedy. Hal ini berarti film tersebut merupakan film dengan Genres Comedy. Sampai di sini, telah berhasil dilakukan proses identifikasi representasi fitur penting dari setiap kategori genres film dengan fungsi tfidvectorizer sehingga dihasilkan matriks korelasi antara judul film dan kategori genrenya

Selanjutnya, akan dilakukan perhitungan derajat kesamaan antara satu film dengan film lain menggunakan cosine similarity untuk menghasilkan kandidat film yang memiliki kemiripan dan akan direkomendasikan kepada pengguna
"""

# Menghitung cosine similarity pada matrix tf-idf
cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim

"""Pada tahapan ini, akan dihitung nilai cosine similarity dataframe tfidf_matrix yang diperoleh pada tahapan sebelumnya menggunakan fungsi cosine similarity dari library sklearn. Output tahap ini berupa matriks kesamaan antar judul film dalam bentuk array.

"""

# Membuat dataframe dari variabel cosine_sim dengan baris dan kolom berupa judul film
cosine_sim_df = pd.DataFrame(cosine_sim, index=data['title'], columns=data['title'])
print('Shape:', cosine_sim_df.shape)

# Melihat similarity matrix pada setiap film
cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

"""## Mendapatkan Rekomendasi"""

def movie_recommendations(nama_movie, similarity_data=cosine_sim_df, items=data[['title', 'genres']], k=10):

    # Mengambil data dengan menggunakan argpartition untuk melakukan partisi secara tidak langsung sepanjang sumbu yang diberikan
    # Dataframe diubah menjadi numpy
    # Range(start, stop, step)
    index = similarity_data.loc[:,nama_movie].to_numpy().argpartition(
        range(-1, -k, -1))

    # Mengambil data dengan similarity terbesar dari index yang ada
    closest = similarity_data.columns[index[-1:-(k+2):-1]]

    # Drop nama_resto agar nama resto yang dicari tidak muncul dalam daftar rekomendasi
    closest = closest.drop(nama_movie, errors='ignore')

    return pd.DataFrame(closest).merge(items).head(k)

"""Sebagai contoh, akan diterapkan rekomendasi film yang mirip dengan judul film Dish, The (2001). Film Dist, The (2001) merupakan film dengan genres Comedy sehingga harapannya rekomendasi yang diberikan adalah film yang bergenre Comedy juga"""

data[data.title.eq('Dish, The (2001)')]

"""Untuk mendapatkan rekomendasi, tinggal dilakukan pemanggilan terhadap fungsi yang telah didefinisikan sebelumnya"""

# Mendapatkan rekomendasi film yang mirip dengan Dish, The (2001)
movie_recommendations('Dish, The (2001)')

"""Dapat dilihat bahwa sistem telah berhasil merekomendasikan top 10 film yang mirip dengan Dish, The (2001). Semua film yang direkomendasikan memiliki kategori Comedy yang berarti memiliki kesamaan genres dengan film Dish, The (2001)

## Evaluasi Hasil Rekomendasi Content Based Filtering

Metrik evaluasi yang digunakan untuk mengukur hasil rekomendasi Content Based Filtering yaitu Precision. Precision adalah rasio antara jumlah item relevan yang direkomendasikan dengan jumlah total item yang direkomendasikan,  sehingga nantinya fungsi akan mengambil daftar film rekomendasi, membandingkan genre film target dengan genre film rekomendasi, lalu menghitung jumlah film yang relevan dibagi K. Dalam contoh ini, precision bernilai 1.0, yang berarti semua 10 film rekomendasi memiliki minimal satu genre yang sama dengan film "Dish, The (2001)", sehingga hasilnya sempurna.
"""

def precision_at_k(recommended_movies, target_movie, items, k=10):

    target_genres = set(items.loc[items['title'] == target_movie, 'genres'].iloc[0].split('|'))
    recommended_genres = items.loc[items['title'].isin(recommended_movies), 'genres'].apply(lambda x: set(x.split('|')))

    relevancy_count = recommended_genres.apply(lambda x: len(target_genres.intersection(x)) > 0).sum()
    return relevancy_count / k

# Contoh penggunaan
movie_name = "Dish, The (2001)"
recommended_df = movie_recommendations(movie_name, cosine_sim_df, data, k=10)
recommended_movies = recommended_df['title'].tolist()

precision_k = precision_at_k(recommended_movies, movie_name, data, k=10)
print(f'Precision: {precision_k:.2f}')

"""# Collaborative Filtering

# Data Understanding
Dataset yang digunakan untuk model dengan pendekatan Collaborative Filtering menggunakan data hasil penggabungan dari movies.csv dan ratings.csv. Oleh karena itu, dilakukan penggabungan dua dataframe yaitu movies.csv dan ratings.csv (df2 dan df1) berdasarkan kolom movieId yang ada di kedua dataframe. Proses ini menggunakan metode penggabungan inner join, yang hanya akan menyertakan baris yang memiliki kecocokan pada kolom movieId di kedua dataframe. Hasilnya adalah dataframe baru df yang berisi informasi gabungan dari kedua dataframe tersebut
"""

df = pd.merge(df2, df1, on='movieId', how='inner')
df

df.info()

"""### Pengecekan Missing Value
Tidak ditemukan missing value pada dataframe hasil panggabungan ini
"""

df.isnull().sum()

"""### Pengecekan dan Hapus Duplikasi Data"""

# Membuang data duplikat pada variabel preparation
#df = df.drop_duplicates('movieId')
df = df.drop_duplicates(subset=['movieId', 'userId'])
df

"""# Data Preparation

Pada tahap ini dilakukan persiapan data untuk menyandikan (encode) fitur userId dan movieId ke dalam indeks integer
"""

# Mengubah userID menjadi list tanpa nilai yang sama
user_ids = df['userId'].unique().tolist()
print('list userId: ', user_ids)

# Melakukan encoding userID
user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
print('encoded userId : ', user_to_user_encoded)

# Melakukan proses encoding angka ke ke userID
user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}
print('encoded angka ke userId: ', user_encoded_to_user)

# Mengubah placeID menjadi list tanpa nilai yang sama
movie_ids = df['movieId'].unique().tolist()

# Melakukan proses encoding placeID
movie_to_movie_encoded = {x: i for i, x in enumerate(movie_ids)}

# Melakukan proses encoding angka ke placeID
movie_encoded_to_movie = {i: x for i, x in enumerate(movie_ids)}

"""Kemudian, dilakukan pemetaan userId dan movieId ke dalam dataframe yang berkaitan"""

# Mapping userID ke dataframe user
df['user'] = df['userId'].map(user_to_user_encoded)

# Mapping placeID ke dataframe resto
df['movie'] = df['movieId'].map(movie_to_movie_encoded)

"""Dilakukan tahap pengecekan jumlah user dan jumlah film. Didapatkan bahwa jumlah user sebanyak 610. Sedangkan, jumlah judul film sebanyak 9724"""

# Mendapatkan jumlah user
num_users = len(user_to_user_encoded)
print(num_users)

# Mendapatkan jumlah film
num_movie = len(movie_encoded_to_movie)
print(num_movie)

"""Mengubah rating menjadi tipe data float"""

# Mengubah rating menjadi nilai float
df['rating'] = df['rating'].values.astype(np.float32)

# Nilai minimum rating
min_rating = min(df['rating'])

# Nilai maksimal rating
max_rating = max(df['rating'])

print('Number of User: {}, Number of Movie: {}, Min Rating: {}, Max Rating: {}'.format(
    num_users, num_movie, min_rating, max_rating
))

"""# Membagi Data untuk Training dan Validasi
pada tahap ini dilakukan pembagian data menjadi data training dan validasi dengan proporsi 80:20. Namun, sebelum melakukan pembagian data training dan validasi perlu dilakukan penentuan variabel fitur dan target. Variabel fiturnya sendiri ada dua yaitu user dan movie. Sedangkan variabel target berupa rating film yang telah dinormalisasi dalam rentang 0 hingga 1 menggunakan Min-Max Scaling
"""

from sklearn.model_selection import train_test_split
# Membuat variabel x untuk mencocokkan data user dan film menjadi satu value
x = df[['user', 'movie']].values

# Membuat variabel y untuk membuat rating dari hasil
y = df['rating'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values

# Membagi menjadi 80% data train dan 20% data validasi
x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=42)


print(x, y)

"""# Inisasi dan Train Model
Pada tahap ini dilakukan pembuatan model rekomendasi menggunakan RecommenderNet. Model ini menggunakan dua embedding layer untuk merepresentasikan pengguna dan film dalam bentuk vektor laten dengan inisialisasi He Normal agar pelatihan lebih stabil serta regularisasi L2 untuk mencegah overfitting.

Embedding yang telah dibuat kemudian diflatten dan digabungkan menggunakan Concatenate(), sehingga informasi dari pengguna dan film dapat diproses bersama. Model memiliki satu hidden layer dengan 64 neuron dan aktivasi ReLU untuk menangkap hubungan non-linear antara pengguna dan film. Selain itu, terdapat lapisan Dropout 0.6 untuk mencegah overfitting dan Batch Normalization untuk menstabilkan distribusi input. Pada  lapisan output terdiri dari satu neuron tanpa aktivasi yang menghasilkan prediksi rating film.
"""

class RecommenderNet(tf.keras.Model):
    def __init__(self, num_users, num_movies, embedding_size, **kwargs):
        super(RecommenderNet, self).__init__(**kwargs)

        # Embedding Layers dengan Regularisasi Lebih Tinggi
        self.user_embedding = layers.Embedding(
            num_users, embedding_size, embeddings_initializer='he_normal',
            embeddings_regularizer=keras.regularizers.l2(0.05)
        )
        self.movie_embedding = layers.Embedding(
            num_movies, embedding_size, embeddings_initializer='he_normal',
            embeddings_regularizer=keras.regularizers.l2(0.05)
        )

        # Fully Connected Layers
        self.flatten_user = layers.Flatten()
        self.flatten_movie = layers.Flatten()
        self.concat = layers.Concatenate()

        self.dense1 = layers.Dense(64, activation="relu")  # Kurangi ukuran
        self.dropout = layers.Dropout(0.6)  # Dropout lebih agresif
        self.batch_norm = layers.BatchNormalization()
        self.dense2 = layers.Dense(1)  # Output tanpa sigmoid

    def call(self, inputs):
        user_vector = self.flatten_user(self.user_embedding(inputs[:, 0]))
        movie_vector = self.flatten_movie(self.movie_embedding(inputs[:, 1]))

        x = self.concat([user_vector, movie_vector])
        x = self.dense1(x)
        x = self.dropout(x)
        x = self.batch_norm(x)
        output = self.dense2(x)

        return output

"""Setelah arsitektur model selesai dibuat, langkah selanjutnya adalah menginisialisasi model dengan embedding size sebesar 50, yang berfungsi untuk merepresentasikan pengguna dan film dalam bentuk vektor laten. Model dikompilasi menggunakan Mean Squared Error (MSE) sebagai fungsi loss karena tugas utamanya adalah regresi, serta menggunakan optimizer Adam dengan learning rate kecil agar pelatihan lebih stabil. Untuk evaluasi, digunakan Root Mean Squared Error (RMSE) yang lebih mudah diinterpretasikan dibandingkan MSE.

Selain itu, digunakan juga dua callback yaitu ReduceLROnPlateau yang menurunkan learning rate secara otomatis saat val_loss stagnan dan EarlyStopping yang menghentikan pelatihan jika val_loss tidak membaik selama beberapa epoch guna mencegah overfitting.
"""

# Inisialisasi Model
embedding_size = 50
model = RecommenderNet(num_users, num_movie, embedding_size)

# Callback
lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(
    monitor='val_loss', factor=0.5, patience=5, min_lr=1e-5
)
early_stopping = tf.keras.callbacks.EarlyStopping(
    monitor='val_loss', patience=5, min_delta=0.001, restore_best_weights=True
)

# Compile Model
model.compile(
    loss=tf.keras.losses.MeanSquaredError(),
    optimizer=keras.optimizers.Adam(learning_rate=0.00005),  # Learning rate lebih kecil
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

""" Model dilatih dengan batch size 64 dan maksimal 50 epoch menggunakan model.fit(). Dataset validasi digunakan untuk mengevaluasi kinerja model setiap epoch, sementara callback yang telah diterapkan memastikan proses pelatihan tetap optimal dan tidak mengalami penurunan performa."""

# Train Model
history = model.fit(
    x_train, y_train,
    batch_size=64,
    epochs=20,
    validation_data=(x_val, y_val),
    callbacks=[lr_scheduler, early_stopping]
)

model.summary()

"""## Visualisasi Metrik"""

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('model_metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""Berdasarkan plot grafik tersebut, proses training model cukup smooth dan model konvergen pada epoch sekitar 5. Dari proses ini diperoleh nilai error RMSE akhir pada data training sebesar 0.1973 dan error RMSE pada data validasi sebesar 0.2005. Nilai ini menunjukkan bahwa model memiliki generalisasi yang baik karena perbedaan error antara training dan validasi sangat kecil. Selain itu, tidak terdapat indikasi overfitting karena kurva training dan validasi berjalan sejajar tanpa ada kesenjangan yang signifikan.


"""

# Menampilkan metrik selama pelatihan
train_rmse = history.history['root_mean_squared_error']
val_rmse = history.history['val_root_mean_squared_error']

# Menampilkan hasil metrik
print("RMSE pada Data Pelatihan: ", train_rmse[-1])  # RMSE terakhir pada pelatihan
print("RMSE pada Data Validasi: ", val_rmse[-1])    # RMSE terakhir pada validasi

"""# Mendapatkan Rekomendasi

Untuk mendapatkan rekomendasi film, pertama-tama sistem akan menerima user_id sebagai input dan memastikan bahwa ID tersebut sudah dalam bentuk terkode.
Selanjutnya, sistem mengambil daftar film yang sudah pernah ditonton oleh pengguna dan menyimpannya dalam variabel watched_movies. Kemudian, daftar movie_ids_to_predict dibuat dengan mengambil seluruh movie yang tersedia lalu menghilangkan film yang sudah ditonton pengguna menggunakan np.setdiff1d()karena sistem hanya akan merekomendasikan film yang belum pernah ditonton.

Setelah itu, ID film yang akan diprediksi dikonversi ke dalam bentuk terkode, lalu dibuat array input dengan menggabungkan ID pengguna yang sudah dikodekan dengan ID film yang akan diprediksi. Model kemudian memprediksi rating untuk setiap film dalam daftar tersebut, dan hasil prediksi ini digunakan untuk menentukan film dengan rating tertinggi.

Akhirnya, sistem mengambil 10 film terbaik berdasarkan prediksi rating tertinggi. Dengan cara ini, rekomendasi yang diberikan lebih personal karena didasarkan pada film yang belum ditonton tetapi memiliki kemungkinan besar untuk disukai pengguna.
"""

def make_recommendation(model, user_id, num_recommendations=10):
    # Memastikan bahwa user_id sudah dalam bentuk terkode
    user_encoded = user_to_user_encoded.get(user_id)
    if user_encoded is None:
        raise ValueError("UserID tidak ditemukan dalam ID pengguna yang terkode.")

    # Mengambil film yang belum pernah ditonton oleh pengguna
    watched_movies = df[df['userId'] == user_id]['movieId'].values
    all_movie_ids = np.array(movie_ids)
    movie_ids_to_predict = np.setdiff1d(all_movie_ids, watched_movies)

    # Melakukan encoding movie ID
    movie_ids_encoded = [movie_to_movie_encoded.get(movie_id) for movie_id in movie_ids_to_predict]

    # Membuat array input untuk prediksi, menggabungkan user dan movie
    user_encoded_array = np.array([user_encoded] * len(movie_ids_encoded))
    movie_ids_encoded_array = np.array(movie_ids_encoded)

    # Gabungkan menjadi satu array dua dimensi
    input_array = np.column_stack((user_encoded_array, movie_ids_encoded_array))

    # Memprediksi rating untuk setiap film yang belum ditonton
    predictions = model.predict(input_array)

    # Mengambil film dengan rating tertinggi
    top_ratings_indices = predictions.flatten().argsort()[-num_recommendations:][::-1]
    recommended_movie_ids_encoded = [movie_ids_encoded_array[x] for x in top_ratings_indices]

    # Mengembalikan ID film yang direkomendasikan
    recommended_movie_ids = [movie_encoded_to_movie.get(movie_encoded) for movie_encoded in recommended_movie_ids_encoded]

    # Menampilkan informasi film yang direkomendasikan
    recommended_movies = df[df['movieId'].isin(recommended_movie_ids)].drop_duplicates(subset='movieId')[['movieId', 'title','genres']]
    return recommended_movies

# Memilih ID pengguna acak
random_user_id = np.random.choice(user_ids)

# Tampilkan film teratas yang dinilai oleh user
top_rated_movies_by_user = df[df['userId'] == random_user_id].sort_values(by='rating', ascending=False).head(5)

# Menampilkan rekomendasi untuk pengguna acak
recommended_movies = make_recommendation(model, random_user_id, num_recommendations=10)

# Menampilkan top film by user
print(f"Film Teratas yang Dinilai oleh User: {random_user_id}")
display(top_rated_movies_by_user[['userId', 'rating', 'title', 'genres']])

# Menampilkan hasil rekomendasi
print("\n")
print(f"Rekomendasi film untuk User: {random_user_id}")
display(recommended_movies[['title','genres']])

"""Model berhasil memberikan rekomendasi film kepada user. Sebagai contoh, hasil di atas adalah rekomendasi untuk user dengan id 113. Dari output tersebut,dapat dibandingkan antara Film with high ratings from user dan Top 10 film recommendation untuk user. Dapat dilihat bahwa beberapa film rekomendasi memiliki genres yang sesuai dengan rating user.

# Dampak terhadap Business Understanding

Sistem rekomendasi film yang dikembangkan memiliki dampak signifikan terhadap pemahaman bisnis, terutama dalam hal meningkatkan pengalaman pengguna di platform streaming. Berikut adalah beberapa aspek utama dampaknya:
1.   Menjawab Problem Statement dan Mencapai Goals
*   Sistem rekomendasi film dengan pendekatan Content Based Filtering berhasil memberikan Top-N rekomendasi film berdasarkan genre favorit pengguna
*   Sistem rekomendasi film dengan pendekatan Collaborative Filtering berhasil memberikan rekomendasi film yang belum pernah ditonton oleh pengguna berdasarkan rating yang telah diberikan
*   Berdasarkan evaluasi menggunakan metrik Precision pada sistem rekomendasi Content Based Filterting dan RMSE pada sistem rekomendasi Collaborative Filtering menunjukkan bahwa kedua model sistem rekomendasi memiliki kinerja yang baik dalam memberikan rekomendasi yang relevan dan akurat, serta memenuhi tujuan untuk memberikan rekomendasi film yang lebih personal dan sesuai dengan preferensi pengguna.

2.   Dampak dari Solusi Statement
*   Sistem Rekomendasi dengan pendeketan Content Based Filtering dan Collaborative Filtering keduanya berhasil memberikan hasil rekomendasi yang akurat dan relevan yang dibuktikan dengan nilai Evaluasi menggunakan metrik Precision untuk Content-Based Filtering dan RMSE untuk Collaborative Filtering menunjukkan nilai yang sangat baik.
*  Dengan adanya sistem rekomendasi film ini, dapat dijadikan pertimbangan bagi pihak platform streaming film dalam meningkatkan pengalaman pengguna dengan cara yang lebih personal dan menyenangkan sehingga mendorong pengguna untuk lebih lama bertahan di platform dan memperbesar peluang peningkatan engagement.

# Kesimpulan

Model dengan pendekatan Content-Based Filtering dan Collaborative Filtering mampu memberikan rekomendasi yang relevan dengan baik kepada pengguna.
Content-Based Filtering lebih fokus pada kesamaan genre film yang sudah ditonton pengguna, sementara Collaborative Filtering berbasis jaringan saraf, memanfaatkan pola rating dari pengguna lain untuk menyarankan film yang belum pernah ditonton. Kedua pendekatan ini memberikan nilai tambah bagi platform streaming sehingga diharapkan dapat meningkatkan pengalaman pengguna dengan rekomendasi yang lebih personal dan sesuai selera.
"""